{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages available (each page is 10 articles): \n",
      "economics :  4564\n",
      "politics :  19069\n",
      "espionage :  1173\n",
      "global+warming :  2022\n",
      "clinton :  9168\n",
      "sanders :  3497\n",
      "guns :  3356\n",
      "cancer :  7599\n",
      "sex :  9963\n"
     ]
    }
   ],
   "source": [
    "from nytsnippetgetter import get_data\n",
    "import time\n",
    "\n",
    "# start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# get available number of pages for each topic. Each page is equivalent to 10 articles\n",
    "topics=['economics','politics','espionage','global+warming', 'clinton', 'sanders', 'guns', 'cancer', 'sex']\n",
    "npages = [1500,1000,500,100,100,100,100,100,100]\n",
    "# topics=['economics','politics']\n",
    "get_data(topics, BEGINDATE = 20131213, LIMITS=True) # articles written since 2013-December-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:  ['economics', 'politics', 'espionage', 'global+warming', 'clinton', 'sanders', 'guns', 'cancer', 'sex']\n",
      "NPages:  [1500, 1000, 500, 100, 100, 100, 100, 100, 100] \n",
      "\n",
      "Total documents:  36000\n",
      "Started download...\n",
      "economics is done | 1500/3600\n",
      "politics is done | 2500/3600\n",
      "espionage is done | 3000/3600\n",
      "global+warming is done | 3100/3600\n",
      "clinton is done | 3200/3600\n",
      "sanders is done | 3300/3600\n",
      "guns is done | 3400/3600\n",
      "cancer is done | 3500/3600\n",
      "sex is done | 3600/3600\n",
      "\n",
      "Done in  390.8875939846039 seconds\n"
     ]
    }
   ],
   "source": [
    "# download article data \n",
    "articles = get_data(TOPICS = topics, NPAGES = npages, BEGINDATE = 20131213)\n",
    "# articles = get_data(TOPICS = topics, NPAGES = [150,100,50,10,10,10,10,10,10])\n",
    "# articles = get_data(TOPICS = topics, BEGINDATE = 20131213, NPAGES = [15,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Psychology in economics',\n",
       " 'author': '',\n",
       " 'date_modified': '2008-11-03T23:52:36Z',\n",
       " 'date_published': '1921-04-10T00:00:00Z',\n",
       " 'keywords': [{'name': 'persons', 'value': 'ECONOMICS'},\n",
       "  {'name': 'glocations', 'value': 'RUSSIA'},\n",
       "  {'name': 'glocations', 'value': 'ENGLAND'},\n",
       "  {'name': 'organizations', 'value': 'INTERNATL ARMY'},\n",
       "  {'name': 'subject', 'value': 'BOLSHEVIST GOVT'},\n",
       "  {'name': 'subject', 'value': 'LABOR'},\n",
       "  {'name': 'subject', 'value': 'EDITORIALS'}],\n",
       " 'lead_paragraph': None,\n",
       " 'nytclass': None,\n",
       " 'section_name': [],\n",
       " 'snippet': 'Psychology in economics',\n",
       " 'title': 'REDS FORMING ARMY OF ALL NATIONS; Said to Plan a Huge Force to Enforce Dictates of the ThirdInternationale.',\n",
       " 'user_topic': 'economics',\n",
       " 'weburl': 'http://query.nytimes.com/gst/abstract.html?res=9901E0D9103FEE3ABC4852DFB266838A639EDE'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles is a list of objects with each object being one document\n",
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of articles\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Nones. Good to go.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Psychology in economics',\n",
       " 'GASOLINE prices on the South Fork are consistently 20 to 50 cents more per gallon than in other areas of Long Island. But the recent run-up in gasoline prices to record levels has been a rude awakening for some South Fork residents.',\n",
       " 'we have to make these comparisons, and we either do them implicitly or explicitly,” said Dana Goldman, director of health <strong>economics</strong> at the RAND Corporation, a nonprofit research institute in Santa Monica, Calif. To make the']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some articles are missing lead paragraph and abstract. just use snippets for now\n",
    "data = [ x['snippet'] for x in articles]\n",
    "\n",
    "# check if data has Nones\n",
    "nonesidx = [data.index(x) for x in data if x == None and len(x) > 0]\n",
    "if len(nonesidx) > 0:\n",
    "    print(\"You have nones. Below are indices of articles.\")\n",
    "    print(nonesidx)\n",
    "else:\n",
    "    print(\"No Nones. Good to go.\")\n",
    "    \n",
    "data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'sex', 'sex', 'sex']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# article topics\n",
    "label = [ x['user_topic'] for x in articles]\n",
    "label[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 1267) (36000,) \n",
      "\n",
      "Number of unique words (features) across all docs:  1267 \n",
      "\n",
      "(docid, wordid) TFIDF \n",
      "\n",
      "  (0, 394)\t0.404664224029\n",
      "  (0, 571)\t0.328499578152\n",
      "  (0, 900)\t0.853425388036\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "vectorizer = TfidfVectorizer() # Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "le = preprocessing.LabelEncoder() # Encode labels with value between 0 and n_classes-1.\n",
    "\n",
    "vectors = vectorizer.fit_transform(data) \n",
    "target = le.fit_transform(label)\n",
    "\n",
    "print(vectors.shape, target.shape,'\\n')\n",
    "print(\"Number of unique words (features) across all docs: \", vectors.shape[1], '\\n')\n",
    "print(\"(docid, wordid) TFIDF\", '\\n')\n",
    "print(vectors[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.13888888888889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of non-zero components by sample, i.e. average number of words with non-zero IDFxTF by article\n",
    "vectors.nnz / float(vectors.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24120, 1267) (11880, 1267)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, target, test_size=0.33, random_state=1729)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  1.0\n",
      "Accuracy:  1.0\n",
      "Confusion matrix:\n",
      " Predicted    0    1     2     3    4    5     6    7    8\n",
      "True                                                     \n",
      "0          337    0     0     0    0    0     0    0    0\n",
      "1            0  321     0     0    0    0     0    0    0\n",
      "2            0    0  4910     0    0    0     0    0    0\n",
      "3            0    0     0  1670    0    0     0    0    0\n",
      "4            0    0     0     0  334    0     0    0    0\n",
      "5            0    0     0     0    0  343     0    0    0\n",
      "6            0    0     0     0    0    0  3327    0    0\n",
      "7            0    0     0     0    0    0     0  313    0\n",
      "8            0    0     0     0    0    0     0    0  325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "clf = MultinomialNB(alpha=2)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"F-score: \", metrics.f1_score(y_test, pred, average='weighted'))\n",
    "print(\"Accuracy: \", metrics.precision_score(y_test, pred, average='weighted'))\n",
    "print(\"Confusion matrix:\\n\", pd.crosstab(y_test, pred, rownames=['True'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer: immunotherapy of breast and the her as for strong cancer\n",
      "clinton: with and trump art in the hillary hill strong clinton\n",
      "economics: he and that of to psychology in the economics strong\n",
      "espionage: by in and new had his to strong espionage the\n",
      "global+warming: has to group planet the climate strong warming change global\n",
      "guns: night of fort increase at roses for strong the guns\n",
      "politics: to by may province havana oriente arms washington of the\n",
      "sanders: host weight 59 woman bernie show larry strong the sanders\n",
      "sex: production partly of its strangers in and the strong sex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "        \n",
    "# print ten most important words for each topic\n",
    "show_top10(clf, vectorizer, le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651.8414900302887 seconds\n"
     ]
    }
   ],
   "source": [
    "# end timer\n",
    "print(time.time()-start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:  ['economics', 'politics', 'espionage', 'global+warming', 'clinton', 'sanders', 'guns', 'cancer', 'sex']\n",
      "NPages:  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10] \n",
      "\n",
      "Total documents:  1000\n",
      "Started download...\n",
      "economics is done | 10/100\n",
      "politics is done | 20/100\n",
      "espionage is done | 30/100\n",
      "global+warming is done | 40/100\n",
      "clinton is done | 50/100\n",
      "sanders is done | 60/100\n",
      "guns is done | 70/100\n",
      "cancer is done | 80/100\n",
      "sex is done | 90/100\n",
      "\n",
      "Done in  26.307778120040894 seconds\n",
      "(900, 1267) (900,) \n",
      "\n",
      "Number of unique words (features) across all docs:  1267 \n",
      "\n",
      "(docid, wordid) TFIDF \n",
      "\n",
      "  (0, 394)\t0.404664224029\n",
      "  (0, 571)\t0.328499578152\n",
      "  (0, 900)\t0.853425388036\n"
     ]
    }
   ],
   "source": [
    "# test the model on articles written before 2013-December-13\n",
    "test = get_data(TOPICS = topics, ENDDATE = 20131213, NPAGES = [10,10,10,10,10,10,10,10,10,10])\n",
    "test_data = [ x['snippet'] for x in test]\n",
    "test_label = [ x['user_topic'] for x in test]\n",
    "\n",
    "test_vectors = vectorizer.transform(test_data) \n",
    "test_target = le.transform(test_label)\n",
    "\n",
    "print(test_vectors.shape, test_target.shape,'\\n')\n",
    "print(\"Number of unique words (features) across all docs: \", vectors.shape[1], '\\n')\n",
    "print(\"(docid, wordid) TFIDF\", '\\n')\n",
    "print(vectors[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  1.0\n",
      "Accuracy:  1.0\n",
      "Confusion matrix:\n",
      " Predicted    0    1    2    3    4    5    6    7    8\n",
      "True                                                  \n",
      "0          100    0    0    0    0    0    0    0    0\n",
      "1            0  100    0    0    0    0    0    0    0\n",
      "2            0    0  100    0    0    0    0    0    0\n",
      "3            0    0    0  100    0    0    0    0    0\n",
      "4            0    0    0    0  100    0    0    0    0\n",
      "5            0    0    0    0    0  100    0    0    0\n",
      "6            0    0    0    0    0    0  100    0    0\n",
      "7            0    0    0    0    0    0    0  100    0\n",
      "8            0    0    0    0    0    0    0    0  100\n"
     ]
    }
   ],
   "source": [
    "pred_test = clf.predict(test_vectors)\n",
    "print(\"F-score: \", metrics.f1_score(test_target, pred_test, average='weighted'))\n",
    "print(\"Accuracy: \", metrics.precision_score(test_target, pred_test, average='weighted'))\n",
    "print(\"Confusion matrix:\\n\", pd.crosstab(test_target, pred_test, rownames=['True'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classify by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DWIGHT GARNER', 'BEN KENIGSBERG', '', 'LESLIE BERGER']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# article author\n",
    "label = [ x['author'] for x in articles]\n",
    "label[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24120, 1267) (11880, 1267)\n"
     ]
    }
   ],
   "source": [
    "target = le.fit_transform(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, target, test_size=0.33, random_state=1729)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  1.0\n",
      "Accuracy:  1.0\n",
      "Confusion matrix:\n",
      " Predicted    0    1   2   3   4   5   6    7   8    9  ...  49   50   51  52  \\\n",
      "True                                                   ...                     \n",
      "0          4507    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "1             0  482   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "2             0    0  39   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "3             0    0   0  65   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "4             0    0   0   0  38   0   0    0   0    0 ...   0    0    0   0   \n",
      "5             0    0   0   0   0  35   0    0   0    0 ...   0    0    0   0   \n",
      "6             0    0   0   0   0   0  34    0   0    0 ...   0    0    0   0   \n",
      "7             0    0   0   0   0   0   0  190   0    0 ...   0    0    0   0   \n",
      "8             0    0   0   0   0   0   0    0  26    0 ...   0    0    0   0   \n",
      "9             0    0   0   0   0   0   0    0   0  171 ...   0    0    0   0   \n",
      "10            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "11            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "12            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "13            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "14            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "15            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "16            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "17            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "18            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "19            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "20            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "21            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "22            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "23            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "24            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "25            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "26            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "27            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "28            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "29            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "30            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "31            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "32            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "33            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "34            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "35            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "36            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "37            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "38            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "39            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "40            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "41            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "42            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "43            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "44            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "45            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "46            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "47            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "48            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "49            0    0   0   0   0   0   0    0   0    0 ...  33    0    0   0   \n",
      "50            0    0   0   0   0   0   0    0   0    0 ...   0  163    0   0   \n",
      "51            0    0   0   0   0   0   0    0   0    0 ...   0    0  493   0   \n",
      "52            0    0   0   0   0   0   0    0   0    0 ...   0    0    0  35   \n",
      "53            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "54            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "55            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "56            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "57            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "58            0    0   0   0   0   0   0    0   0    0 ...   0    0    0   0   \n",
      "\n",
      "Predicted   53  54  55  56   57  58  \n",
      "True                                 \n",
      "0            0   0   0   0    0   0  \n",
      "1            0   0   0   0    0   0  \n",
      "2            0   0   0   0    0   0  \n",
      "3            0   0   0   0    0   0  \n",
      "4            0   0   0   0    0   0  \n",
      "5            0   0   0   0    0   0  \n",
      "6            0   0   0   0    0   0  \n",
      "7            0   0   0   0    0   0  \n",
      "8            0   0   0   0    0   0  \n",
      "9            0   0   0   0    0   0  \n",
      "10           0   0   0   0    0   0  \n",
      "11           0   0   0   0    0   0  \n",
      "12           0   0   0   0    0   0  \n",
      "13           0   0   0   0    0   0  \n",
      "14           0   0   0   0    0   0  \n",
      "15           0   0   0   0    0   0  \n",
      "16           0   0   0   0    0   0  \n",
      "17           0   0   0   0    0   0  \n",
      "18           0   0   0   0    0   0  \n",
      "19           0   0   0   0    0   0  \n",
      "20           0   0   0   0    0   0  \n",
      "21           0   0   0   0    0   0  \n",
      "22           0   0   0   0    0   0  \n",
      "23           0   0   0   0    0   0  \n",
      "24           0   0   0   0    0   0  \n",
      "25           0   0   0   0    0   0  \n",
      "26           0   0   0   0    0   0  \n",
      "27           0   0   0   0    0   0  \n",
      "28           0   0   0   0    0   0  \n",
      "29           0   0   0   0    0   0  \n",
      "30           0   0   0   0    0   0  \n",
      "31           0   0   0   0    0   0  \n",
      "32           0   0   0   0    0   0  \n",
      "33           0   0   0   0    0   0  \n",
      "34           0   0   0   0    0   0  \n",
      "35           0   0   0   0    0   0  \n",
      "36           0   0   0   0    0   0  \n",
      "37           0   0   0   0    0   0  \n",
      "38           0   0   0   0    0   0  \n",
      "39           0   0   0   0    0   0  \n",
      "40           0   0   0   0    0   0  \n",
      "41           0   0   0   0    0   0  \n",
      "42           0   0   0   0    0   0  \n",
      "43           0   0   0   0    0   0  \n",
      "44           0   0   0   0    0   0  \n",
      "45           0   0   0   0    0   0  \n",
      "46           0   0   0   0    0   0  \n",
      "47           0   0   0   0    0   0  \n",
      "48           0   0   0   0    0   0  \n",
      "49           0   0   0   0    0   0  \n",
      "50           0   0   0   0    0   0  \n",
      "51           0   0   0   0    0   0  \n",
      "52           0   0   0   0    0   0  \n",
      "53         330   0   0   0    0   0  \n",
      "54           0  65   0   0    0   0  \n",
      "55           0   0  26   0    0   0  \n",
      "56           0   0   0  22    0   0  \n",
      "57           0   0   0   0  158   0  \n",
      "58           0   0   0   0    0  33  \n",
      "\n",
      "[59 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"F-score: \", metrics.f1_score(y_test, pred, average='weighted'))\n",
    "print(\"Accuracy: \", metrics.precision_score(y_test, pred, average='weighted'))\n",
    "print(\"Confusion matrix:\\n\", pd.crosstab(y_test, pred, rownames=['True'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": washington strong exposure for and economics of in the psychology\n",
      "ALEX BERENSON: either monica corporation goldman them calif comparisons rand we make\n",
      "AMY CHOZICK: victories bearing delegates thirds far leads string direction more sanders\n",
      "AMY HARMON: treatment approach months toxic championed promising results standard for cancer\n",
      "ANDREW R. CHOW: guitarist axl duties frontman angus will guns roses ac dc\n",
      "ANNIE CORREAL: son previously 21 alpert month endings spends defender obit kalyan\n",
      "BEN KENIGSBERG: 91 wfmu hudson radio hardly film station 90 as city\n",
      "BENJAMIN WEISER: americans sporyshev buryakov prisoners based television four the he mr\n",
      "BRYAN MILLER: really vibrant sights always williamsburg lefferts willing clinton hill she\n",
      "CEYLAN YEGINSU: closed potential journalists prompting awaited whether istanbul outrage concerns trial\n",
      "CHARLES ISHERWOOD: thomas lucas season timing du hnath top trust continuing here\n",
      "CHARLES M. BLOW: bash thursday planned cnn unsettling comment fight me if democratic\n",
      "CHOE SANG-HUN: abroad ranking revealed high also confirmed rare had south military\n",
      "CINDI LEIVE: seems landscape 26 303 pp right girls girl orenstein peggy\n",
      "CNBC: exhortation existed of his support research immunotherapy parker sean discusses\n",
      "DEAN R. LEIMER, and SELIG D. LESNOY: negative support impact hand does designed saving offset recommendations however\n",
      "DENISE GRADY: disease expected enough is the 000 breast still strong cancer\n",
      "DWIGHT GARNER: betjeman lust written senior writes novels front presenting bring among\n",
      "ERIK PIEPENBURG: male someone company relationship younger having female frisky blogger is\n",
      "FARAH STOCKMAN: rally april farmer protested away peers carrying philadelphia prison so\n",
      "FIRST DRAFT: released vermont income promises weeks questioning rival 2014 tax following\n",
      "GARDINER HARRIS: work barriers 2003 vice biden selecting will to cancer her\n",
      "GEORGE R. HARRIS: 77 field 75 german fired was it the whiz bang\n",
      "GINA KOLATA: type strong panel tumor downgraded thousands patients officially as cancer\n",
      "JAMES PONIEWOZIK: jeffrey thing sidekick hank preparing garry kingsley sanders the larry\n",
      "JAVIER C. HERNÁNDEZ: documents sign combat threats technician 150 beijing china selling aggressive\n",
      "JEREMY EGNER: him creating later invite performances carson tonight host show guest\n",
      "JOHN KOBLIN: economy devote communicating accessible carter offered mass administration to he\n",
      "JOHN SCHWARTZ: general statements eric investigation was is strong exxon global warming\n",
      "JON PARELES: brings arena injured founding left together reunited festival keep foot\n",
      "KAREN ALEXANDER: into others virility gym unwittingly trap rats turbocharged quest step\n",
      "KAREN W. ARENSON: lesnoy disclosed findings calculation paper stirred repeating the in feldstein\n",
      "KEN JAWOROWSKI: strong writing moments place script intriguing saves the sex partly\n",
      "LESLIE BERGER: pioneers behavioral around require cooperation since considered techniques 1940 masters\n",
      "LIAM STACK: climate would outline affected investors resolution force energy giant profitability\n",
      "LISA SANDERS, M.D: gain readers unexplained solve old year why woman weight 59\n",
      "MARK MAZZETTI: intelligence pakistan 83 leesburg 70s role contra career in his\n",
      "MARTIN S. FELDSTEIN: how years financial decide deal next few problems increasing the\n",
      "MATT RICHTEL and FERNANDA SANTOS: making safeguarding let calculated consume communities watersheds blazes concentrating decisions\n",
      "MICHAEL WINERIP, MICHAEL SCHWIRTZ and TOM ROBBINS: northern murderers agency past brutality investigations pep unusually bad series\n",
      "NEIL GENZLINGER: dementia thank instance sprung documentaries impactful loss easier more as\n",
      "NO POLITICS: mcgillicudy 22 nnt _____ committee gratify substituted jan politician some\n",
      "PATRICK HEALY and MAGGIE HABERMAN: presidential primary tuesday with dealt severe back blow commanding unexpectedly\n",
      "PAUL KRUGMAN: mostly musing wrong 1999 brad depression repost it review got\n",
      "PETER KEEPNEWS: dark 1998 comics behind stand ran 1980s show sanders larry\n",
      "Pamela G. Hollie: venture sisters suspense twin begun winston guccione publisher will magazine\n",
      "REUTERS: sarcastically ted state calling achievement donald downplayed truly cruz trump\n",
      "ROGER COHEN: the has politics change home planet therefore body come am\n",
      "SAMANTH SUBRAMANIAN: das survey chandra became britain secret sarat carry enchanted instead\n",
      "SIMONE GUBLER: classrooms carve spectacle sporting appalled unarmed administrators zones guns into\n",
      "STEVEN ERLANGER: successes discovered bbc colleagues deny everything described stasi recently urged\n",
      "STEWART AIN: run rude 20 gallon areas cents south gasoline fork prices\n",
      "SYLVIANE GOLD: antiquated course clunky arrived gone delightful only matter laptop time\n",
      "Special to The New York Times: hughes establishing proclamation coolidge embargo shipment against action munitions the\n",
      "THE ASSOCIATED PRESS: kelly felony indicted accused champion pellet middleweight pavlik ohio matt\n",
      "TIMOTHY EGAN: regarding church desire apostolic skeptics stirring teachings pope catholics approves\n",
      "WILLIAM B. GAIL: comprehend longstanding scientists century picture predicted significant hence our occur\n",
      "Wireless to THE NEW YORK TIMES: acclaimed wireless by strong espionage play hackett london walter new\n",
      "YAMICHE ALCINDOR: mrs bill strong unemployed post citizens situation five 2000 clinton\n"
     ]
    }
   ],
   "source": [
    "# print ten most important words for each topic\n",
    "show_top10(clf, vectorizer, le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify by author using articles from different time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:  ['economics', 'politics', 'espionage', 'global+warming', 'clinton', 'sanders', 'guns', 'cancer', 'sex']\n",
      "NPages:  [150, 100, 50, 10, 10, 10, 10, 10, 10] \n",
      "\n",
      "Total documents:  3600\n",
      "Started download...\n",
      "economics is done | 150/360\n",
      "politics is done | 250/360\n",
      "espionage is done | 300/360\n",
      "global+warming is done | 310/360\n",
      "clinton is done | 320/360\n",
      "sanders is done | 330/360\n",
      "guns is done | 340/360\n",
      "cancer is done | 350/360\n",
      "sex is done | 360/360\n",
      "\n",
      "Done in  47.70070290565491 seconds\n",
      "{'user_topic': 'economics', 'abstract': 'Psychology in economics', 'weburl': 'http://query.nytimes.com/gst/abstract.html?res=9901E0D9103FEE3ABC4852DFB266838A639EDE', 'author': '', 'nytclass': None, 'date_modified': '2008-11-03T23:52:36Z', 'keywords': [{'name': 'persons', 'value': 'ECONOMICS'}, {'name': 'glocations', 'value': 'RUSSIA'}, {'name': 'glocations', 'value': 'ENGLAND'}, {'name': 'organizations', 'value': 'INTERNATL ARMY'}, {'name': 'subject', 'value': 'BOLSHEVIST GOVT'}, {'name': 'subject', 'value': 'LABOR'}, {'name': 'subject', 'value': 'EDITORIALS'}], 'lead_paragraph': None, 'date_published': '1921-04-10T00:00:00Z', 'section_name': [], 'snippet': 'Psychology in economics', 'title': 'REDS FORMING ARMY OF ALL NATIONS; Said to Plan a Huge Force to Enforce Dictates of the ThirdInternationale.'}\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "# Classify by author using articles from different time periods\n",
    "articles = get_data(TOPICS = topics, NPAGES = [150,100,50,10,10,10,10,10,10])\n",
    "print(articles[0])\n",
    "# number of articles\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Nones. Good to go.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Psychology in economics',\n",
       " 'GASOLINE prices on the South Fork are consistently 20 to 50 cents more per gallon than in other areas of Long Island. But the recent run-up in gasoline prices to record levels has been a rude awakening for some South Fork residents.',\n",
       " 'we have to make these comparisons, and we either do them implicitly or explicitly,” said Dana Goldman, director of health <strong>economics</strong> at the RAND Corporation, a nonprofit research institute in Santa Monica, Calif. To make the']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some articles are missing lead paragraph and abstract. just use snippets for now\n",
    "data = [ x['snippet'] for x in articles]\n",
    "\n",
    "# check if data has Nones\n",
    "nonesidx = [data.index(x) for x in data if x == None and len(x) > 0]\n",
    "if len(nonesidx) > 0:\n",
    "    print(\"You have nones. Below are indices of articles.\")\n",
    "    print(nonesidx)\n",
    "else:\n",
    "    print(\"No Nones. Good to go.\")\n",
    "    \n",
    "data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DWIGHT GARNER', 'LAURIE GOODSTEIN', 'BEN KENIGSBERG', '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# article authors\n",
    "label = [ x['author'] for x in articles]\n",
    "label[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2412, 1251) (1188, 1251)\n"
     ]
    }
   ],
   "source": [
    "vectors = vectorizer.fit_transform(data)\n",
    "target = le.fit_transform(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, target, test_size=0.33, random_state=1729)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  0.834503858119\n",
      "Accuracy:  0.800488961534\n",
      "Confusion matrix:\n",
      " Predicted   0   1   2   4   6   7   8   10  11  13 ...  39  40  42  44  47  \\\n",
      "True                                               ...                       \n",
      "0          453   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "1            0  48   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "2            4   0   1   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "3            4   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "4            0   0   0   2   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "6            0   0   0   0  17   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "7            0   0   0   0   0   2   0   0   0   0 ...   0   0   0   0   0   \n",
      "8            0   0   0   0   0   0  14   0   0   0 ...   0   0   0   0   0   \n",
      "9            0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "10           0   0   0   0   0   0   0   1   0   0 ...   0   0   0   0   0   \n",
      "11           0   0   0   0   0   0   0   0  30   0 ...   0   0   0   0   0   \n",
      "12           0   0   0   0   0   0   0   0   0   5 ...   0   0   0   0   0   \n",
      "13           0   0   0   0   0   0   0   0   0  55 ...   0   0   0   0   0   \n",
      "14           9   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "15           0   0   0   0   0   0   0   0   0   0 ...   0   7   0   0   0   \n",
      "16           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "17           0   0   0   0   0   0   0   0   0   0 ...   0   0   6   0   0   \n",
      "18           0   0   0   0   0   0   0   0   0   0 ...   0   0   2   0   0   \n",
      "19           0   5   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "20           3   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "21           4   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "22           5   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "23           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "24           5   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "25           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "26           3   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "27           4   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "28           3   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "29           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "30           4   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "31           1   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "32           0   3   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "33           4   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "34           6   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "35           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "36           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "37           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "38           8   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "39           0   0   0   0   0   0   0   0   0   0 ...   1   0   0   0   0   \n",
      "40           0   0   0   0   0   0   0   0   0   0 ...   0  35   0   0   0   \n",
      "41           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "42           0   0   0   0   0   0   0   0   0   0 ...   0   0  54   0   0   \n",
      "43           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "44           0   0   0   0   0   0   0   0   0   0 ...   0   0   0  18   0   \n",
      "45           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "46           3   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "47           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0  15   \n",
      "48           4   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "49           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "50           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "51           3   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "52           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "53           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "54           6   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "55           0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "56           3   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   \n",
      "\n",
      "Predicted  49  50  52  53  55  \n",
      "True                           \n",
      "0           0   0   0   0   0  \n",
      "1           0   0   0   0   0  \n",
      "2           0   0   0   0   0  \n",
      "3           0   0   0   0   0  \n",
      "4           0   0   0   0   0  \n",
      "6           0   0   0   0   0  \n",
      "7           0   0   0   0   0  \n",
      "8           0   0   0   0   0  \n",
      "9           0   0   0   0   0  \n",
      "10          0   0   0   0   0  \n",
      "11          0   0   0   0   0  \n",
      "12          0   0   0   0   0  \n",
      "13          0   0   0   0   0  \n",
      "14          0   0   0   0   0  \n",
      "15          0   0   0   0   0  \n",
      "16          0   0   0   0   0  \n",
      "17          0   0   0   0   0  \n",
      "18          0   0   0   0   0  \n",
      "19          0   0   0   0   0  \n",
      "20          0   0   0   0   0  \n",
      "21          0   0   0   0   0  \n",
      "22          0   0   0   0   0  \n",
      "23          0   0   0   0   0  \n",
      "24          0   0   0   0   0  \n",
      "25          0   0   0   0   0  \n",
      "26          0   0   0   0   0  \n",
      "27          0   0   0   0   0  \n",
      "28          0   0   0   0   0  \n",
      "29          0   0   0   0   0  \n",
      "30          0   0   0   0   0  \n",
      "31          0   0   0   0   0  \n",
      "32          0   0   0   0   0  \n",
      "33          0   0   0   0   0  \n",
      "34          0   0   0   0   0  \n",
      "35          0   0   0   0   0  \n",
      "36          0   0   0   0   0  \n",
      "37          0   3   0   0   0  \n",
      "38          0   0   0   0   0  \n",
      "39          0   0   0   0   0  \n",
      "40          0   0   0   0   0  \n",
      "41          0   0   0   0   0  \n",
      "42          0   0   0   0   0  \n",
      "43          0   0   0   0   0  \n",
      "44          0   0   0   0   0  \n",
      "45          0   0   0   0   0  \n",
      "46          0   0   0   0   0  \n",
      "47          0   0   0   0   0  \n",
      "48          0   0   0   0   0  \n",
      "49         12   0   0   0   0  \n",
      "50          0  40   0   0   0  \n",
      "51          0   0   0   0   0  \n",
      "52          0   0  39   0   0  \n",
      "53          0   0   0   5   0  \n",
      "54          0   0   0   0   0  \n",
      "55          0   0   0   0  17  \n",
      "56          0   0   0   0   0  \n",
      "\n",
      "[56 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tpot/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/tpot/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"F-score: \", metrics.f1_score(y_test, pred, average='weighted'))\n",
    "print(\"Accuracy: \", metrics.precision_score(y_test, pred, average='weighted'))\n",
    "print(\"Confusion matrix:\\n\", pd.crosstab(y_test, pred, rownames=['True'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.801\n",
      "Completeness: 0.991\n",
      "V-measure: 0.886\n",
      "Adjusted Rand-Index: 0.796\n",
      "Silhouette Coefficient: 0.458\n"
     ]
    }
   ],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(y_test, pred))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(y_test, pred))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(y_test, pred))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(y_test, pred))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X_test, pred, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
